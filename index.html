<!DOCTYPE html>
<html>
<body>


<h1> <center>Gala Nicolas Kaufman</center> </h1>


<h2>Contact Information</h2>

<ul>
<li><a href="mailto:gala.nicolaskaufman@gmail.com">Email</a></li>
<li><a href="http://www.linkedin.com/in/gala-nicolas-kaufman-8b51938b">LinkedIn</a></li>
<li><a href="http://github.com/galank">GitHub</a></li>
</ul>

<h2>Background</h2>

<p>
I received a PhD in physics from Cornell in 2014. From 2009 to 2014 I was a member of the Compact Muon Solenoid (CMS) collaboration at the Large Hadron Collider (LHC) at CERN (Switzerland), and worked primarily on new physics searches. 
</p>

<p>
After graduate school I made the transition to industry and have been employed as a data scientist at <a href="http://hiqlabs.com">hiQ Labs</a>, a people analytics SaaS company, since 2015. My work there has focused on predicting employee turnover. 
</p>

<h2>Resume Highlights</h2>

<h3>Skills</h3>

<h4>Programming</h4>
<ul>
<li><b>C++</b> -- Proficiency in developing custom modeling and analysis software. Familiarity with specialized
mathematical and statistical libraries.</li>
<li><b>Python</b> -- Experience in building and maintaining data 
pipelines encompassing data collection, processing and analysis.</li>
<li><b>R</b> -- Familiarity with modeling tools and libraries.</li>
</ul>

<h4>Analysis tools and techniques</h4>
<ul>
<li><b>Statistics</b></li>
<li><b>Machine Learning</b></li>
</ul>

<h3>Experience</h3>

<p>
<b>hiQ Labs</b>, San Francisco, CA <br>
2015-Present <br>
<i>Data Scientist</i> <br>
<ul>
<li>Contribute to and maintain data pipeline.</li>
<li>Develop logging and reporting tools for data pipeline monitoring.</li>
<li>Oversee monthly release of updated employee turnover predictions to corporate customers.</li>
</ul>
</p>

<p>
<b>The CMS Experiment</b>, CERN, Switzerland <br>
2009-2014 <br>
<i>Graduate Research Assistant</i> <br>
<ul>
<li>Thesis analysis: Search for pair-produced resonances decaying to top quarks and jets with the CMS detector at the LHC.</li>
<li>Performed large-scale data-mining on âˆ¼ 100 TB dataset containing hundreds of billions of events.</li>
<li>Developed custom software framework for rapid data visualization and analysis.</li>
<li>Ran sophisticated statistical analysis on data using specialized mathematical and statistical libraries.</li>
</ul>
</p>

</body>
</html>
